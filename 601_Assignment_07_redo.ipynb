{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "peripheral-hollow",
   "metadata": {},
   "source": [
    "For each file, remove punctuation and stop words. The list of words per file should be unique. Do not include URLs or phone numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acute-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "insured-swimming",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HaChoi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "south-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HaChoi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "experienced-plane",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['grasp', 'tags', 'adjective', 'annotations', 'two', 'sentence', 'When', 'applied', 'usually', 'grammatical', 'annotated', 'around', 'verb', 'manner', 'comparable', 'number', 'information', 'part', 'make', 'comprising', 'translations', 'Other', 'kind', 'aid', 'fully', 'texts', 'semantics', 'process', 'contextualised', 'noun', 'levels', 'also', 'Multilingual', 'used', 'added', 'called', 'An', 'annotation', 'various', 'sentences', 'glossing', 'word', 'subjected', 'recognition', 'knowledge', 'corpus', 'parsed', 'Markov', 'hidden', 'derived', 'million', 'considered', 'aligned', 'working', 'exposure', 'main', 'research', 'particular', 'formation', 'example', 'one', 'target', 'phrases', 'comparison', 'create', 'types', 'subject', 'learners', 'allows', 'Treebanks', 'analysis', 'processing', 'models', 'type', 'identifying', 'interlinear', 'formatted', 'form', 'much', 'lists', 'trained', 'Another', 'entire', 'languages', 'means', 'tagging', 'work', 'words', 'teaching', 'acquired', 'fragments', 'useful', 'indicating', 'speech', 'Machine', 'use', 'parallel', 'including', 'To', 'first', 'Parsed', 'order', 'machine', 'segments', 'prerequisite', 'containing', 'translation', 'Such', 'algorithms', 'specially', 'etc', 'purposes', 'text', 'equivalent', 'enabling', 'language', 'alignment', 'difficulty', 'ensuring', 'frequency', 'lemma', 'effective', 'known', 'corpora', 'annotating', 'researchers', 'completely', 'In', 'translating', 'linguistic', 'authentic', 'second', 'smaller', 'morphology', 'There', 'consistently', 'often', 'Corpora', 'users', 'computational', 'contain', 'structured', 'possible', 'foreign', 'exploit', 'using', 'linguistics', 'content', 'may', 'base', 'three', 'writing', 'The', 'cover']]\n"
     ]
    }
   ],
   "source": [
    "# load docx file \n",
    "\n",
    "doc = Document('week_8_documents/week_8_document1.docx')\n",
    "\n",
    "fullText = \"\"\n",
    "\n",
    "for para in doc.paragraphs:\n",
    "    fullText += para.text\n",
    "    doc_tokens = word_tokenize(fullText)\n",
    "    \n",
    "# filter out stop words from docx file\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "doc_sentence = []\n",
    "\n",
    "for words in doc_tokens:\n",
    "    if words not in stop_words:\n",
    "        doc_sentence.append(words)\n",
    "        \n",
    "# filter out punctuation from docx file\n",
    "\n",
    "doc_words = []\n",
    "\n",
    "for word1 in doc_sentence:\n",
    "    if word1.isalpha():\n",
    "        doc_words.append(word1)\n",
    "\n",
    "# filter out unique words\n",
    "        \n",
    "unique_words = [list(set(doc_words))]\n",
    "\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mathematical-pakistan",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['impress', 'even', 'recent', 'initial', 'professional', 'condition', 'defusing', 'class', 'grateful', 'publish', 'spindles', 'picture', 'portrait', 'Students', 'acme', 'period', 'suddenly', 'interval', 'simply', 'man', 'inevitably', 'mostly', 'anywhere', 'another', 'render', 'peak', 'conversations', 'mouth', 'ways', 'personality', 'needed', 'ignorant', 'everybody', 'fair', 'side', 'recalled', 'eventually', 'way', 'extinguished', 'connection', 'wake', 'disappearing', 'mayor', 'type', 'broader', 'retire', 'Stories', 'much', 'reflex', 'academic', 'elaborate', 'classes', 'displayed', 'nothing', 'sees', 'social', 'Proudly', 'lighting', 'reasons', 'Joy', 'orgasmic', 'still', 'Aristotle', 'painting', 'He', 'reticular', 'encounters', 'fascination', 'adrenocorticotropic', 'saw', 'hypoxia', 'conventions', 'whether', 'spontaneous', 'ask', 'enjoyed', 'regarding', 'take', 'managed', 'situation', 'In', 'Yawning', 'origin', 'often', 'On', 'corner', 'enough', 'conclusion', 'spice', 'hand', 'campus', 'stopwatch', 'loss', 'monograph', 'The', 'dean', 'cared', 'unreadable', 'reflected', 'right', 'megaphone', 'inspiratory', 'field', 'learning', 'cure', 'Yawns', 'wind', 'theories', 'understand', 'curiosity', 'made', 'As', 'dollars', 'avalanche', 'lasted', 'tried', 'without', 'An', 'led', 'calming', 'Am', 'either', 'efforts', 'kidnapping', 'life', 'repeatedly', 'phase', 'rate', 'erection', 'contagion', 'one', 'represented', 'Why', 'brainstem', 'least', 'manuscript', 'heavy', 'asking', 'famous', 'physiologic', 'reputation', 'covering', 'evening', 'finished', 'developed', 'paroxysmal', 'mere', 'sat', 'ruined', 'phone', 'years', 'ignored', 'long', 'arousal', 'Boring', 'neuromuscular', 'gradually', 'conceal', 'noting', 'Bedtime', 'yawn', 'harmlessly', 'exams', 'closing', 'thing', 'painted', 'Sometimes', 'proud', 'questions', 'devising', 'pharmacological', 'complex', 'boring', 'value', 'disguised', 'quite', 'Anthology', 'For', 'bed', 'science', 'appointment', 'act', 'owner', 'possible', 'flame', 'expiration', 'accepted', 'hundred', 'unfortunate', 'expertise', 'remember', 'presenting', 'recipient', 'rejected', 'hung', 'cell', 'problems', 'wait', 'beeline', 'search', 'remarkable', 'Dr', 'length', 'perish', 'upon', 'fetal', 'someone', 'project', 'Are', 'stretching', 'could', 'But', 'thanks', 'seeing', 'yawns', 'perhaps', 'suspected', 'back', 'hearing', 'excused', 'Insomniacs', 'Not', 'served', 'moment', 'borderline', 'Sadly', 'intended', 'countless', 'concentrate', 'used', 'inquisitive', 'minor', 'selection', 'joke', 'fall', 'exaggeration', 'urgent', 'correlations', 'epidemic', 'inhibition', 'gather', 'nearly', 'Yawn', 'hypothalamic', 'concerts', 'face', 'fail', 'plot', 'Vickers', 'article', 'happy', 'somniferous', 'missed', 'stifle', 'research', 'seated', 'room', 'started', 'people', 'surreptitiously', 'complete', 'bachelor', 'role', 'foremost', 'time', 'entire', 'work', 'susceptibility', 'quotations', 'suffered', 'showing', 'awaken', 'relation', 'something', 'receptions', 'everyone', 'keep', 'derive', 'Often', 'drifts', 'rude', 'mesmerizing', 'else', 'Renaissance', 'apparently', 'I', 'President', 'path', 'would', 'ingenuity', 'paper', 'uncontrollable', 'relaxing', 'rarely', 'soft', 'equally', 'terrorist', 'priceless', 'dated', 'At', 'warm', 'become', 'phenomenon', 'invitations', 'duration', 'They', 'world', 'laboratories', 'particularly', 'done', 'kept', 'briefly', 'breakthroughs', 'see', 'meticulous', 'bystanders', 'fondly', 'received', 'classroom', 'tones', 'lectures', 'reviewing', 'professor', 'expert', 'data', 'ovation', 'carefully', 'asleep', 'Realizing', 'office', 'lids', 'quietly', 'discussions', 'cocktail', 'peptides', 'frequently', 'systems', 'suicidal', 'came', 'hears', 'paralinguistic', 'rumored', 'number', 'wedding', 'make', 'insomnia', 'fully', 'mate', 'parties', 'afflicted', 'precise', 'death', 'reality', 'mention', 'groundbreaking', 'also', 'placed', 'nation', 'believed', 'called', 'obtain', 'discussion', 'hoped', 'da', 'considered', 'behind', 'almost', 'defense', 'students', 'flickering', 'remembered', 'seemed', 'spoken', 'unconscious', 'middle', 'swallow', 'eyes', 'unable', 'subject', 'Soon', 'dulcet', 'While', 'immediacy', 'gestation', 'Earl', 'book', 'popularize', 'day', 'never', 'dwindled', 'encounter', 'urinates', 'wall', 'bright', 'yawning', 'notes', 'hysterical', 'meetings', 'trigger', 'artist', 'It', 'comfortable', 'His', 'career', 'desperately', 'mechanisms', 'tomorrow', 'temporary', 'certainly', 'short', 'audit', 'alarm', 'dopaminergic', 'sleep', 'help', 'topic', 'effort', 'involved', 'share', 'awake', 'nonetheless', 'bring', 'This', 'Contagious', 'finally', 'new', 'donkey', 'serotoninergic', 'Vinci', 'Meanwhile', 'areas', 'Leonardo', 'doubly', 'satisfaction', 'reached', 'bad', 'writing', 'additional', 'fascinating', 'Even', 'conferences', 'audiences']]\n"
     ]
    }
   ],
   "source": [
    "# load text file\n",
    "\n",
    "text_file = open('week_8_documents/week_8_document2.txt', 'rt')\n",
    "\n",
    "text = text_file.read()\n",
    "\n",
    "no_url = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "# filter out stop words from the text file \n",
    "\n",
    "text_tokens = word_tokenize(no_url)\n",
    "\n",
    "text_sentence = [] \n",
    "\n",
    "for texts in text_tokens:\n",
    "    if texts not in stop_words:\n",
    "        text_sentence.append(texts)\n",
    "        \n",
    "# filter out punctuation from the text file\n",
    "        \n",
    "text_words = []\n",
    "\n",
    "for word in text_sentence:\n",
    "    if word.isalpha():\n",
    "        text_words.append(word)\n",
    "\n",
    "# filter out unique words\n",
    "        \n",
    "unique_texts = [list(set(text_words))]\n",
    "\n",
    "print(unique_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-charles",
   "metadata": {},
   "source": [
    "Produce a single .dat file containing the name of the file in quotes, a colon, then a list of words separated by commas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adequate-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary as a .dat file\n",
    "\n",
    "a = {'week_8_document1.docx': unique_words, 'week_8_document2.txt': unique_texts}\n",
    "with open('output_file.dat', 'w') as f:\n",
    "    f.write(\"{\\n\")\n",
    "    for k in a.keys():\n",
    "        f.write(\"'{}':'{}'\\n\".format(k, a[k]))\n",
    "    f.write(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "understanding-distinction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "'week_8_document1.docx':'[['grasp', 'tags', 'adjective', 'annotations', 'two', 'sentence', 'When', 'applied', 'usually', 'grammatical', 'annotated', 'around', 'verb', 'manner', 'comparable', 'number', 'information', 'part', 'make', 'comprising', 'translations', 'Other', 'kind', 'aid', 'fully', 'texts', 'semantics', 'process', 'contextualised', 'noun', 'levels', 'also', 'Multilingual', 'used', 'added', 'called', 'An', 'annotation', 'various', 'sentences', 'glossing', 'word', 'subjected', 'recognition', 'knowledge', 'corpus', 'parsed', 'Markov', 'hidden', 'derived', 'million', 'considered', 'aligned', 'working', 'exposure', 'main', 'research', 'particular', 'formation', 'example', 'one', 'target', 'phrases', 'comparison', 'create', 'types', 'subject', 'learners', 'allows', 'Treebanks', 'analysis', 'processing', 'models', 'type', 'identifying', 'interlinear', 'formatted', 'form', 'much', 'lists', 'trained', 'Another', 'entire', 'languages', 'means', 'tagging', 'work', 'words', 'teaching', 'acquired', 'fragments', 'useful', 'indicating', 'speech', 'Machine', 'use', 'parallel', 'including', 'To', 'first', 'Parsed', 'order', 'machine', 'segments', 'prerequisite', 'containing', 'translation', 'Such', 'algorithms', 'specially', 'etc', 'purposes', 'text', 'equivalent', 'enabling', 'language', 'alignment', 'difficulty', 'ensuring', 'frequency', 'lemma', 'effective', 'known', 'corpora', 'annotating', 'researchers', 'completely', 'In', 'translating', 'linguistic', 'authentic', 'second', 'smaller', 'morphology', 'There', 'consistently', 'often', 'Corpora', 'users', 'computational', 'contain', 'structured', 'possible', 'foreign', 'exploit', 'using', 'linguistics', 'content', 'may', 'base', 'three', 'writing', 'The', 'cover']]'\n",
      "'week_8_document2.txt':'[['impress', 'even', 'recent', 'initial', 'professional', 'condition', 'defusing', 'class', 'grateful', 'publish', 'spindles', 'picture', 'portrait', 'Students', 'acme', 'period', 'suddenly', 'interval', 'simply', 'man', 'inevitably', 'mostly', 'anywhere', 'another', 'render', 'peak', 'conversations', 'mouth', 'ways', 'personality', 'needed', 'ignorant', 'everybody', 'fair', 'side', 'recalled', 'eventually', 'way', 'extinguished', 'connection', 'wake', 'disappearing', 'mayor', 'type', 'broader', 'retire', 'Stories', 'much', 'reflex', 'academic', 'elaborate', 'classes', 'displayed', 'nothing', 'sees', 'social', 'Proudly', 'lighting', 'reasons', 'Joy', 'orgasmic', 'still', 'Aristotle', 'painting', 'He', 'reticular', 'encounters', 'fascination', 'adrenocorticotropic', 'saw', 'hypoxia', 'conventions', 'whether', 'spontaneous', 'ask', 'enjoyed', 'regarding', 'take', 'managed', 'situation', 'In', 'Yawning', 'origin', 'often', 'On', 'corner', 'enough', 'conclusion', 'spice', 'hand', 'campus', 'stopwatch', 'loss', 'monograph', 'The', 'dean', 'cared', 'unreadable', 'reflected', 'right', 'megaphone', 'inspiratory', 'field', 'learning', 'cure', 'Yawns', 'wind', 'theories', 'understand', 'curiosity', 'made', 'As', 'dollars', 'avalanche', 'lasted', 'tried', 'without', 'An', 'led', 'calming', 'Am', 'either', 'efforts', 'kidnapping', 'life', 'repeatedly', 'phase', 'rate', 'erection', 'contagion', 'one', 'represented', 'Why', 'brainstem', 'least', 'manuscript', 'heavy', 'asking', 'famous', 'physiologic', 'reputation', 'covering', 'evening', 'finished', 'developed', 'paroxysmal', 'mere', 'sat', 'ruined', 'phone', 'years', 'ignored', 'long', 'arousal', 'Boring', 'neuromuscular', 'gradually', 'conceal', 'noting', 'Bedtime', 'yawn', 'harmlessly', 'exams', 'closing', 'thing', 'painted', 'Sometimes', 'proud', 'questions', 'devising', 'pharmacological', 'complex', 'boring', 'value', 'disguised', 'quite', 'Anthology', 'For', 'bed', 'science', 'appointment', 'act', 'owner', 'possible', 'flame', 'expiration', 'accepted', 'hundred', 'unfortunate', 'expertise', 'remember', 'presenting', 'recipient', 'rejected', 'hung', 'cell', 'problems', 'wait', 'beeline', 'search', 'remarkable', 'Dr', 'length', 'perish', 'upon', 'fetal', 'someone', 'project', 'Are', 'stretching', 'could', 'But', 'thanks', 'seeing', 'yawns', 'perhaps', 'suspected', 'back', 'hearing', 'excused', 'Insomniacs', 'Not', 'served', 'moment', 'borderline', 'Sadly', 'intended', 'countless', 'concentrate', 'used', 'inquisitive', 'minor', 'selection', 'joke', 'fall', 'exaggeration', 'urgent', 'correlations', 'epidemic', 'inhibition', 'gather', 'nearly', 'Yawn', 'hypothalamic', 'concerts', 'face', 'fail', 'plot', 'Vickers', 'article', 'happy', 'somniferous', 'missed', 'stifle', 'research', 'seated', 'room', 'started', 'people', 'surreptitiously', 'complete', 'bachelor', 'role', 'foremost', 'time', 'entire', 'work', 'susceptibility', 'quotations', 'suffered', 'showing', 'awaken', 'relation', 'something', 'receptions', 'everyone', 'keep', 'derive', 'Often', 'drifts', 'rude', 'mesmerizing', 'else', 'Renaissance', 'apparently', 'I', 'President', 'path', 'would', 'ingenuity', 'paper', 'uncontrollable', 'relaxing', 'rarely', 'soft', 'equally', 'terrorist', 'priceless', 'dated', 'At', 'warm', 'become', 'phenomenon', 'invitations', 'duration', 'They', 'world', 'laboratories', 'particularly', 'done', 'kept', 'briefly', 'breakthroughs', 'see', 'meticulous', 'bystanders', 'fondly', 'received', 'classroom', 'tones', 'lectures', 'reviewing', 'professor', 'expert', 'data', 'ovation', 'carefully', 'asleep', 'Realizing', 'office', 'lids', 'quietly', 'discussions', 'cocktail', 'peptides', 'frequently', 'systems', 'suicidal', 'came', 'hears', 'paralinguistic', 'rumored', 'number', 'wedding', 'make', 'insomnia', 'fully', 'mate', 'parties', 'afflicted', 'precise', 'death', 'reality', 'mention', 'groundbreaking', 'also', 'placed', 'nation', 'believed', 'called', 'obtain', 'discussion', 'hoped', 'da', 'considered', 'behind', 'almost', 'defense', 'students', 'flickering', 'remembered', 'seemed', 'spoken', 'unconscious', 'middle', 'swallow', 'eyes', 'unable', 'subject', 'Soon', 'dulcet', 'While', 'immediacy', 'gestation', 'Earl', 'book', 'popularize', 'day', 'never', 'dwindled', 'encounter', 'urinates', 'wall', 'bright', 'yawning', 'notes', 'hysterical', 'meetings', 'trigger', 'artist', 'It', 'comfortable', 'His', 'career', 'desperately', 'mechanisms', 'tomorrow', 'temporary', 'certainly', 'short', 'audit', 'alarm', 'dopaminergic', 'sleep', 'help', 'topic', 'effort', 'involved', 'share', 'awake', 'nonetheless', 'bring', 'This', 'Contagious', 'finally', 'new', 'donkey', 'serotoninergic', 'Vinci', 'Meanwhile', 'areas', 'Leonardo', 'doubly', 'satisfaction', 'reached', 'bad', 'writing', 'additional', 'fascinating', 'Even', 'conferences', 'audiences']]'\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# display output file \n",
    "\n",
    "with open('output_file.dat', 'r') as f:\n",
    "    text = f.read()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-level",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
